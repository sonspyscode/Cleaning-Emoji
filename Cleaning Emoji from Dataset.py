# -*- coding: utf-8 -*-
"""Cleaning Lagi.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1cLCwGvKwH2s1_gtRXQYPOWcuXodYuCtE
"""

!pip install spacy
!pip install spacymoji

import pandas as pd
import re
import spacy
from spacymoji import Emoji

nlp = spacy.load("en_core_web_sm")
emoji = Emoji(nlp)
nlp.add_pipe("emoji", first=True)

df_ayam = pd.read_csv("dataset-ayam.csv")

df_ayam

def extract_emojies(x):
  doc = nlp(x)
  emojis = [token.text for token in doc if token._.is_emoji]
  
  return emojis

emojies_df_ayam1 = df_ayam['Title'].apply(extract_emojies)

emoji_counts = (emojies_df_ayam1
                .apply(pd.Series) #breaks up the list into seperate columns 
                .stack() #collapses each column into one column
                .value_counts() #counts the frequency of each item
                .rename('Count')
                .sort_values()
                .reset_index()
                .rename(columns={'index':'Emoji'}))
emoji_counts

df_ayam['Title'] = df_ayam['Title'].str.replace('[^a-zA-z0-9.,!?/:;\"\'\s]', '', flags=re.UNICODE)

df_ayam['Title']

def extract_emojies(x):
  doc = nlp(x)
  emojis = [token.text for token in doc if token._.is_emoji]
  
  return emojis

emojies_df_ayam1c = df_ayam['Title'].apply(extract_emojies)

emoji_counts = (emojies_df_ayam1c
                .apply(pd.Series) #breaks up the list into seperate columns 
                .stack() #collapses each column into one column
                .value_counts() #counts the frequency of each item
                .rename('Count')
                .sort_values()
                .reset_index()
                .rename(columns={'index':'Emoji'}))
emoji_counts

df_ayam['Ingredients']= df_ayam['Ingredients'].astype(str)

def extract_emojies(x):
  doc = nlp(x)
  emojis = [token.text for token in doc if token._.is_emoji]
  
  return emojis

emojies_df_ayam1 = df_ayam['Ingredients'].apply(extract_emojies)

emoji_counts = (emojies_df_ayam1
                .apply(pd.Series) #breaks up the list into seperate columns 
                .stack() #collapses each column into one column
                .value_counts() #counts the frequency of each item
                .rename('Count')
                .sort_values()
                .reset_index()
                .rename(columns={'index':'Emoji'}))
emoji_counts

df_ayam['Ingredients'] = df_ayam['Ingredients'].str.replace('[^a-zA-z0-9.,!?/:;\"\'\s]', '', flags=re.UNICODE)
df_ayam['Ingredients']

def extract_emojies(x):
  doc = nlp(x)
  emojis = [token.text for token in doc if token._.is_emoji]
  
  return emojis

emojies_df_ayam2c = df_ayam['Ingredients'].apply(extract_emojies)

emoji_counts = (emojies_df_ayam2c
                .apply(pd.Series) #breaks up the list into seperate columns 
                .stack() #collapses each column into one column
                .value_counts() #counts the frequency of each item
                .rename('Count')
                .sort_values()
                .reset_index()
                .rename(columns={'index':'Emoji'}))
emoji_counts

def extract_emojies(x):
  doc = nlp(x)
  emojis = [token.text for token in doc if token._.is_emoji]
  
  return emojis

emojies_df_ayam1 = df_ayam['URL'].apply(extract_emojies)

emoji_counts = (emojies_df_ayam1
                .apply(pd.Series) #breaks up the list into seperate columns 
                .stack() #collapses each column into one column
                .value_counts() #counts the frequency of each item
                .rename('Count')
                .sort_values()
                .reset_index()
                .rename(columns={'index':'Emoji'}))
emoji_counts

df_ikan = pd.read_csv("dataset-ikan.csv")

df_ikan

def extract_emojies(x):
  doc = nlp(x)
  emojis = [token.text for token in doc if token._.is_emoji]
  
  return emojis

emojies_df_ikan1 = df_ikan['Title'].apply(extract_emojies)

emoji_counts = (emojies_df_ikan1
                .apply(pd.Series) #breaks up the list into seperate columns 
                .stack() #collapses each column into one column
                .value_counts() #counts the frequency of each item
                .rename('Count')
                .sort_values()
                .reset_index()
                .rename(columns={'index':'Emoji'}))
emoji_counts

def extract_emojies(x):
  doc = nlp(x)
  emojis = [token.text for token in doc if token._.is_emoji]
  
  return emojis

emojies_df_ikan2 = df_ikan['Ingredients'].apply(extract_emojies)

emoji_counts = (emojies_df_ikan2
                .apply(pd.Series) #breaks up the list into seperate columns 
                .stack() #collapses each column into one column
                .value_counts() #counts the frequency of each item
                .rename('Count')
                .sort_values()
                .reset_index()
                .rename(columns={'index':'Emoji'}))
emoji_counts

df_ikan['Ingredients'] = df_ikan['Ingredients'].str.replace('[^a-zA-z0-9.,!?/:;\"\'\s]', '', flags=re.UNICODE)
df_ikan['Ingredients']

def extract_emojies(x):
  doc = nlp(x)
  emojis = [token.text for token in doc if token._.is_emoji]
  
  return emojis

emojies_df_ikan2c = df_ikan['Ingredients'].apply(extract_emojies)

emoji_counts = (emojies_df_ikan2c
                .apply(pd.Series) #breaks up the list into seperate columns 
                .stack() #collapses each column into one column
                .value_counts() #counts the frequency of each item
                .rename('Count')
                .sort_values()
                .reset_index()
                .rename(columns={'index':'Emoji'}))
emoji_counts

def extract_emojies(x):
  doc = nlp(x)
  emojis = [token.text for token in doc if token._.is_emoji]
  
  return emojis

emojies_df_ikan3 = df_ikan['URL'].apply(extract_emojies)

emoji_counts = (emojies_df_ikan3
                .apply(pd.Series) #breaks up the list into seperate columns 
                .stack() #collapses each column into one column
                .value_counts() #counts the frequency of each item
                .rename('Count')
                .sort_values()
                .reset_index()
                .rename(columns={'index':'Emoji'}))
emoji_counts

df_kambing = pd.read_csv("dataset-kambing.csv")

df_kambing

def extract_emojies(x):
  doc = nlp(x)
  emojis = [token.text for token in doc if token._.is_emoji]
  
  return emojis

emojies_df_kambing1 = df_kambing['Title'].apply(extract_emojies)

emoji_counts = (emojies_df_kambing1
                .apply(pd.Series) #breaks up the list into seperate columns 
                .stack() #collapses each column into one column
                .value_counts() #counts the frequency of each item
                .rename('Count')
                .sort_values()
                .reset_index()
                .rename(columns={'index':'Emoji'}))
emoji_counts

df_kambing['Title'] = df_kambing['Title'].str.replace('[^a-zA-z0-9.,!?/:;\"\'\s]', '', flags=re.UNICODE)
df_kambing['Title']

def extract_emojies(x):
  doc = nlp(x)
  emojis = [token.text for token in doc if token._.is_emoji]
  
  return emojis

emojies_df_kambing1c = df_kambing['Title'].apply(extract_emojies)

emoji_counts = (emojies_df_kambing1c
                .apply(pd.Series) #breaks up the list into seperate columns 
                .stack() #collapses each column into one column
                .value_counts() #counts the frequency of each item
                .rename('Count')
                .sort_values()
                .reset_index()
                .rename(columns={'index':'Emoji'}))
emoji_counts

df_kambing['Ingredients']= df_kambing['Ingredients'].astype(str)

def extract_emojies(x):
  doc = nlp(x)
  emojis = [token.text for token in doc if token._.is_emoji]
  
  return emojis

emojies_df_kambing2 = df_kambing['Ingredients'].apply(extract_emojies)

emoji_counts = (emojies_df_kambing2
                .apply(pd.Series) #breaks up the list into seperate columns 
                .stack() #collapses each column into one column
                .value_counts() #counts the frequency of each item
                .rename('Count')
                .sort_values()
                .reset_index()
                .rename(columns={'index':'Emoji'}))
emoji_counts

df_kambing['Ingredients'] = df_kambing['Ingredients'].str.replace('[^a-zA-z0-9.,!?/:;\"\'\s]', '', flags=re.UNICODE)
df_kambing['Ingredients']

def extract_emojies(x):
  doc = nlp(x)
  emojis = [token.text for token in doc if token._.is_emoji]
  
  return emojis

emojies_df_kambing2c = df_kambing['Ingredients'].apply(extract_emojies)

emoji_counts = (emojies_df_kambing2c
                .apply(pd.Series) #breaks up the list into seperate columns 
                .stack() #collapses each column into one column
                .value_counts() #counts the frequency of each item
                .rename('Count')
                .sort_values()
                .reset_index()
                .rename(columns={'index':'Emoji'}))
emoji_counts

def extract_emojies(x):
  doc = nlp(x)
  emojis = [token.text for token in doc if token._.is_emoji]
  
  return emojis

emojies_df_kambing3 = df_kambing['URL'].apply(extract_emojies)

emoji_counts = (emojies_df_kambing3
                .apply(pd.Series) #breaks up the list into seperate columns 
                .stack() #collapses each column into one column
                .value_counts() #counts the frequency of each item
                .rename('Count')
                .sort_values()
                .reset_index()
                .rename(columns={'index':'Emoji'}))
emoji_counts

df_sapi = pd.read_csv("dataset-sapi.csv")

df_sapi

def extract_emojies(x):
  doc = nlp(x)
  emojis = [token.text for token in doc if token._.is_emoji]
  
  return emojis

emojies_df_sapi1 = df_sapi['Title'].apply(extract_emojies)

emoji_counts = (emojies_df_sapi1
                .apply(pd.Series) #breaks up the list into seperate columns 
                .stack() #collapses each column into one column
                .value_counts() #counts the frequency of each item
                .rename('Count')
                .sort_values()
                .reset_index()
                .rename(columns={'index':'Emoji'}))
emoji_counts

df_sapi['Ingredients']= df_sapi['Ingredients'].astype(str)

def extract_emojies(x):
  doc = nlp(x)
  emojis = [token.text for token in doc if token._.is_emoji]
  
  return emojis

emojies_df_sapi2 = df_sapi['Ingredients'].apply(extract_emojies)

emoji_counts = (emojies_df_sapi2
                .apply(pd.Series) #breaks up the list into seperate columns 
                .stack() #collapses each column into one column
                .value_counts() #counts the frequency of each item
                .rename('Count')
                .sort_values()
                .reset_index()
                .rename(columns={'index':'Emoji'}))
emoji_counts

df_sapi['Ingredients'] = df_sapi['Ingredients'].str.replace('[^a-zA-z0-9.,!?/:;\"\'\s]', '', flags=re.UNICODE)
df_sapi['Ingredients']

def extract_emojies(x):
  doc = nlp(x)
  emojis = [token.text for token in doc if token._.is_emoji]
  
  return emojis

emojies_df_sapi2c = df_sapi['Ingredients'].apply(extract_emojies)

emoji_counts = (emojies_df_sapi2c
                .apply(pd.Series) #breaks up the list into seperate columns 
                .stack() #collapses each column into one column
                .value_counts() #counts the frequency of each item
                .rename('Count')
                .sort_values()
                .reset_index()
                .rename(columns={'index':'Emoji'}))
emoji_counts

def extract_emojies(x):
  doc = nlp(x)
  emojis = [token.text for token in doc if token._.is_emoji]
  
  return emojis

emojies_df_sapi3 = df_sapi['URL'].apply(extract_emojies)

emoji_counts = (emojies_df_sapi3
                .apply(pd.Series) #breaks up the list into seperate columns 
                .stack() #collapses each column into one column
                .value_counts() #counts the frequency of each item
                .rename('Count')
                .sort_values()
                .reset_index()
                .rename(columns={'index':'Emoji'}))
emoji_counts

df_tahu = pd.read_csv("dataset-tahu.csv")

df_tahu

def extract_emojies(x):
  doc = nlp(x)
  emojis = [token.text for token in doc if token._.is_emoji]
  
  return emojis

emojies_df_tahu1 = df_tahu['Title'].apply(extract_emojies)

emoji_counts = (emojies_df_tahu1
                .apply(pd.Series) #breaks up the list into seperate columns 
                .stack() #collapses each column into one column
                .value_counts() #counts the frequency of each item
                .rename('Count')
                .sort_values()
                .reset_index()
                .rename(columns={'index':'Emoji'}))
emoji_counts

df_tahu['Title'] = df_tahu['Title'].str.replace('[^a-zA-z0-9.,!?/:;\"\'\s]', '', flags=re.UNICODE)
df_tahu['Title']

def extract_emojies(x):
  doc = nlp(x)
  emojis = [token.text for token in doc if token._.is_emoji]
  
  return emojis

emojies_df_tahu1c = df_tahu['Title'].apply(extract_emojies)

emoji_counts = (emojies_df_tahu1c
                .apply(pd.Series) #breaks up the list into seperate columns 
                .stack() #collapses each column into one column
                .value_counts() #counts the frequency of each item
                .rename('Count')
                .sort_values()
                .reset_index()
                .rename(columns={'index':'Emoji'}))
emoji_counts

def extract_emojies(x):
  doc = nlp(x)
  emojis = [token.text for token in doc if token._.is_emoji]
  
  return emojis

emojies_df_tahu2 = df_tahu['Ingredients'].apply(extract_emojies)

emoji_counts = (emojies_df_tahu2
                .apply(pd.Series) #breaks up the list into seperate columns 
                .stack() #collapses each column into one column
                .value_counts() #counts the frequency of each item
                .rename('Count')
                .sort_values()
                .reset_index()
                .rename(columns={'index':'Emoji'}))
emoji_counts

df_tahu['Ingredients'] = df_tahu['Ingredients'].str.replace('[^a-zA-z0-9.,!?/:;\"\'\s]', '', flags=re.UNICODE)
df_tahu['Ingredients']

def extract_emojies(x):
  doc = nlp(x)
  emojis = [token.text for token in doc if token._.is_emoji]
  
  return emojis

emojies_df_tahu2c = df_tahu['Ingredients'].apply(extract_emojies)

emoji_counts = (emojies_df_tahu2c
                .apply(pd.Series) #breaks up the list into seperate columns 
                .stack() #collapses each column into one column
                .value_counts() #counts the frequency of each item
                .rename('Count')
                .sort_values()
                .reset_index()
                .rename(columns={'index':'Emoji'}))
emoji_counts

def extract_emojies(x):
  doc = nlp(x)
  emojis = [token.text for token in doc if token._.is_emoji]
  
  return emojis

emojies_df_tahu3 = df_tahu['URL'].apply(extract_emojies)

emoji_counts = (emojies_df_tahu3
                .apply(pd.Series) #breaks up the list into seperate columns 
                .stack() #collapses each column into one column
                .value_counts() #counts the frequency of each item
                .rename('Count')
                .sort_values()
                .reset_index()
                .rename(columns={'index':'Emoji'}))
emoji_counts

df_telur = pd.read_csv("dataset-telur.csv")

df_telur

def extract_emojies(x):
  doc = nlp(x)
  emojis = [token.text for token in doc if token._.is_emoji]
  
  return emojis

emojies_df_telur1 = df_telur['Title'].apply(extract_emojies)

emoji_counts = (emojies_df_telur1
                .apply(pd.Series) #breaks up the list into seperate columns 
                .stack() #collapses each column into one column
                .value_counts() #counts the frequency of each item
                .rename('Count')
                .sort_values()
                .reset_index()
                .rename(columns={'index':'Emoji'}))
emoji_counts

df_telur['Title'] = df_telur['Title'].str.replace('[^a-zA-z0-9.,!?/:;\"\'\s]', '', flags=re.UNICODE)
df_telur['Title']

def extract_emojies(x):
  doc = nlp(x)
  emojis = [token.text for token in doc if token._.is_emoji]
  
  return emojis

emojies_df_telur1c = df_telur['Title'].apply(extract_emojies)

emoji_counts = (emojies_df_telur1c
                .apply(pd.Series) #breaks up the list into seperate columns 
                .stack() #collapses each column into one column
                .value_counts() #counts the frequency of each item
                .rename('Count')
                .sort_values()
                .reset_index()
                .rename(columns={'index':'Emoji'}))
emoji_counts

df_telur['Ingredients']= df_telur['Ingredients'].astype(str)

def extract_emojies(x):
  doc = nlp(x)
  emojis = [token.text for token in doc if token._.is_emoji]
  
  return emojis

emojies_df_telur2 = df_telur['Ingredients'].apply(extract_emojies)

emoji_counts = (emojies_df_telur2
                .apply(pd.Series) #breaks up the list into seperate columns 
                .stack() #collapses each column into one column
                .value_counts() #counts the frequency of each item
                .rename('Count')
                .sort_values()
                .reset_index()
                .rename(columns={'index':'Emoji'}))
emoji_counts

df_telur['Ingredients'] = df_telur['Ingredients'].str.replace('[^a-zA-z0-9.,!?/:;\"\'\s]', '', flags=re.UNICODE)
df_telur['Ingredients']

def extract_emojies(x):
  doc = nlp(x)
  emojis = [token.text for token in doc if token._.is_emoji]
  
  return emojis

emojies_df_telur2c = df_telur['Ingredients'].apply(extract_emojies)

emoji_counts = (emojies_df_telur2c
                .apply(pd.Series) #breaks up the list into seperate columns 
                .stack() #collapses each column into one column
                .value_counts() #counts the frequency of each item
                .rename('Count')
                .sort_values()
                .reset_index()
                .rename(columns={'index':'Emoji'}))
emoji_counts

def extract_emojies(x):
  doc = nlp(x)
  emojis = [token.text for token in doc if token._.is_emoji]
  
  return emojis

emojies_df_telur3 = df_telur['URL'].apply(extract_emojies)

emoji_counts = (emojies_df_telur3
                .apply(pd.Series) #breaks up the list into seperate columns 
                .stack() #collapses each column into one column
                .value_counts() #counts the frequency of each item
                .rename('Count')
                .sort_values()
                .reset_index()
                .rename(columns={'index':'Emoji'}))
emoji_counts

df_tempe = pd.read_csv("dataset-tempe.csv")

df_tempe

def extract_emojies(x):
  doc = nlp(x)
  emojis = [token.text for token in doc if token._.is_emoji]
  
  return emojis

emojies_df_tempe1 = df_tempe['Title'].apply(extract_emojies)

emoji_counts = (emojies_df_tempe1
                .apply(pd.Series) #breaks up the list into seperate columns 
                .stack() #collapses each column into one column
                .value_counts() #counts the frequency of each item
                .rename('Count')
                .sort_values()
                .reset_index()
                .rename(columns={'index':'Emoji'}))
emoji_counts

df_tempe['Title'] = df_tempe['Title'].str.replace('[^a-zA-z0-9.,!?/:;\"\'\s]', '', flags=re.UNICODE)
df_tempe['Title']

def extract_emojies(x):
  doc = nlp(x)
  emojis = [token.text for token in doc if token._.is_emoji]
  
  return emojis

emojies_df_tempe1c = df_tempe['Title'].apply(extract_emojies)

emoji_counts = (emojies_df_tempe1c
                .apply(pd.Series) #breaks up the list into seperate columns 
                .stack() #collapses each column into one column
                .value_counts() #counts the frequency of each item
                .rename('Count')
                .sort_values()
                .reset_index()
                .rename(columns={'index':'Emoji'}))
emoji_counts

df_tempe['Ingredients']= df_tempe['Ingredients'].astype(str)

def extract_emojies(x):
  doc = nlp(x)
  emojis = [token.text for token in doc if token._.is_emoji]
  
  return emojis

emojies_df_tempe2 = df_tempe['Ingredients'].apply(extract_emojies)

emoji_counts = (emojies_df_tempe2
                .apply(pd.Series) #breaks up the list into seperate columns 
                .stack() #collapses each column into one column
                .value_counts() #counts the frequency of each item
                .rename('Count')
                .sort_values()
                .reset_index()
                .rename(columns={'index':'Emoji'}))
emoji_counts

df_tempe['Ingredients'] = df_tempe['Ingredients'].str.replace('[^a-zA-z0-9.,!?/:;\"\'\s]', '', flags=re.UNICODE)
df_tempe['Ingredients']

def extract_emojies(x):
  doc = nlp(x)
  emojis = [token.text for token in doc if token._.is_emoji]
  
  return emojis

emojies_df_tempe2c = df_tempe['Ingredients'].apply(extract_emojies)

emoji_counts = (emojies_df_tempe2c
                .apply(pd.Series) #breaks up the list into seperate columns 
                .stack() #collapses each column into one column
                .value_counts() #counts the frequency of each item
                .rename('Count')
                .sort_values()
                .reset_index()
                .rename(columns={'index':'Emoji'}))
emoji_counts

def extract_emojies(x):
  doc = nlp(x)
  emojis = [token.text for token in doc if token._.is_emoji]
  
  return emojis

emojies_df_tempe3 = df_tempe['URL'].apply(extract_emojies)

emoji_counts = (emojies_df_tempe3
                .apply(pd.Series) #breaks up the list into seperate columns 
                .stack() #collapses each column into one column
                .value_counts() #counts the frequency of each item
                .rename('Count')
                .sort_values()
                .reset_index()
                .rename(columns={'index':'Emoji'}))
emoji_counts

df_udang = pd.read_csv("dataset-udang.csv")

df_udang

def extract_emojies(x):
  doc = nlp(x)
  emojis = [token.text for token in doc if token._.is_emoji]
  
  return emojis

emojies_df_udang1 = df_udang['Title'].apply(extract_emojies)

emoji_counts = (emojies_df_udang1
                .apply(pd.Series) #breaks up the list into seperate columns 
                .stack() #collapses each column into one column
                .value_counts() #counts the frequency of each item
                .rename('Count')
                .sort_values()
                .reset_index()
                .rename(columns={'index':'Emoji'}))
emoji_counts

df_udang['Title'] = df_udang['Title'].str.replace('[^a-zA-z0-9.,!?/:;\"\'\s]', '', flags=re.UNICODE)
df_udang['Title']

def extract_emojies(x):
  doc = nlp(x)
  emojis = [token.text for token in doc if token._.is_emoji]
  
  return emojis

emojies_df_udang1c = df_udang['Title'].apply(extract_emojies)

emoji_counts = (emojies_df_udang1c
                .apply(pd.Series) #breaks up the list into seperate columns 
                .stack() #collapses each column into one column
                .value_counts() #counts the frequency of each item
                .rename('Count')
                .sort_values()
                .reset_index()
                .rename(columns={'index':'Emoji'}))
emoji_counts

def extract_emojies(x):
  doc = nlp(x)
  emojis = [token.text for token in doc if token._.is_emoji]
  
  return emojis

emojies_df_udang2 = df_udang['Ingredients'].apply(extract_emojies)

emoji_counts = (emojies_df_udang2
                .apply(pd.Series) #breaks up the list into seperate columns 
                .stack() #collapses each column into one column
                .value_counts() #counts the frequency of each item
                .rename('Count')
                .sort_values()
                .reset_index()
                .rename(columns={'index':'Emoji'}))
emoji_counts

df_udang['Ingredients'] = df_udang['Ingredients'].str.replace('[^a-zA-z0-9.,!?/:;\"\'\s]', '', flags=re.UNICODE)
df_udang['Ingredients']

def extract_emojies(x):
  doc = nlp(x)
  emojis = [token.text for token in doc if token._.is_emoji]
  
  return emojis

emojies_df_udang2c = df_udang['Ingredients'].apply(extract_emojies)

emoji_counts = (emojies_df_udang2c
                .apply(pd.Series) #breaks up the list into seperate columns 
                .stack() #collapses each column into one column
                .value_counts() #counts the frequency of each item
                .rename('Count')
                .sort_values()
                .reset_index()
                .rename(columns={'index':'Emoji'}))
emoji_counts

def extract_emojies(x):
  doc = nlp(x)
  emojis = [token.text for token in doc if token._.is_emoji]
  
  return emojis

emojies_df_udang3 = df_udang['URL'].apply(extract_emojies)

emoji_counts = (emojies_df_udang3
                .apply(pd.Series) #breaks up the list into seperate columns 
                .stack() #collapses each column into one column
                .value_counts() #counts the frequency of each item
                .rename('Count')
                .sort_values()
                .reset_index()
                .rename(columns={'index':'Emoji'}))
emoji_counts

from google.colab import files

df_ayam.to_csv('clean_df_ayam.csv', encoding = 'utf-8-sig') 
files.download('clean_df_ayam.csv')

df_testing = pd.read_csv("clean_df_ayam.csv")

df_testing

def extract_emojies(x):
  doc = nlp(x)
  emojis = [token.text for token in doc if token._.is_emoji]
  
  return emojis

emojies_df_testing1 = df_testing['Title'].apply(extract_emojies)

emoji_counts = (emojies_df_testing1
                .apply(pd.Series) #breaks up the list into seperate columns 
                .stack() #collapses each column into one column
                .value_counts() #counts the frequency of each item
                .rename('Count')
                .sort_values()
                .reset_index()
                .rename(columns={'index':'Emoji'}))
emoji_counts

df_testing['Ingredients']= df_testing['Ingredients'].astype(str)

def extract_emojies(x):
  doc = nlp(x)
  emojis = [token.text for token in doc if token._.is_emoji]
  
  return emojis

emojies_df_testing2 = df_testing['Ingredients'].apply(extract_emojies)

emoji_counts = (emojies_df_testing2
                .apply(pd.Series) #breaks up the list into seperate columns 
                .stack() #collapses each column into one column
                .value_counts() #counts the frequency of each item
                .rename('Count')
                .sort_values()
                .reset_index()
                .rename(columns={'index':'Emoji'}))
emoji_counts

def extract_emojies(x):
  doc = nlp(x)
  emojis = [token.text for token in doc if token._.is_emoji]
  
  return emojis

emojies_df_testing3 = df_testing['URL'].apply(extract_emojies)

emoji_counts = (emojies_df_testing3
                .apply(pd.Series) #breaks up the list into seperate columns 
                .stack() #collapses each column into one column
                .value_counts() #counts the frequency of each item
                .rename('Count')
                .sort_values()
                .reset_index()
                .rename(columns={'index':'Emoji'}))
emoji_counts